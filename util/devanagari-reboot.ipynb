{
 "metadata": {
  "name": "",
  "signature": "sha256:7d2f17f2e36039be85ec365eb15df5bb853ae9b7656a538fb8dcacb2131da271"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "# <nbformat>3.0</nbformat>\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "# This fetches the current poems from a private Drupal site accessed via xmlrpc\n",
      "\n",
      "import xmlrpcsettings # this holds a few private settings\n",
      "import xmlrpclib\n",
      "import re\n",
      "import json\n",
      "import urllib\n",
      "import codecs\n",
      "\n",
      "assert xmlrpcsettings.ursite\n",
      "assert xmlrpcsettings.inbookurl\n",
      "\n",
      "proxy = xmlrpclib.Server(xmlrpcsettings.ursite)\n",
      "\n",
      "open_url = urllib.urlopen(xmlrpcsettings.inbookurl)\n",
      "nds=json.load(open_url)\n",
      "items = nds['Items']\n",
      "inbook = []\n",
      "for i in items:\n",
      "    inbook.append( proxy.node.retrieve(i['node']['nid']) )\n",
      "assert len(inbook)==30\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "import myparser\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "def get_trans(n):\n",
      "    return n['body']['und'][0]['value']\n",
      "\n",
      "def clean_trans(x):\n",
      "\n",
      "    x=x.replace(' -o- ','-o-') # join these for now to better extract izafats\n",
      "    x=x.replace('!','')\n",
      "    x=x.replace('^','')\n",
      "    x=x.replace(',',' ')\n",
      "    x=x.replace('?',' ')\n",
      "    x=x.replace('--',' ')\n",
      "    x=x.replace('\\t',' ')\n",
      "    x=x.replace('\"',' ')\n",
      "    x=re.sub('\\s+',' ',x)\n",
      "\n",
      "    x=re.sub(\"^\\s+\",'',x)\n",
      "    x=re.sub(\"\\s+$\",'',x)\n",
      "#    x=x.replace('_','-')\n",
      "    return x\n",
      "def get_lines(x):\n",
      "    return x.split('\\n') # may need to account for extra empty lines at end\n",
      "\n",
      "# <codecell>\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chars = \"[a-z\\(\\):\\-;\\._']+?\"\n",
      "z= '('+chars+'(?:-e '+chars+')*'+')'+'(?: |$)'                                              \n",
      "pattern = re.compile(z,re.UNICODE)\n",
      "\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "words = {}\n",
      "def clean_word(x): # remove brackets\n",
      "    if re.match('\\([^(]',x):\n",
      "         x = x[1:]\n",
      "#         print x\n",
      "    if re.search('[^)]\\)$',x):\n",
      "        x = x[0:-1]\n",
      "    if re.search(':$',x):\n",
      "         x = x[0:-1]\n",
      "    x=re.sub('\\.\\.\\.$','',x)\n",
      "\n",
      "#        print x\n",
      "    return x\n",
      "for i,n in enumerate(inbook):\n",
      "    x = clean_trans(get_trans(n))\n",
      "    lines=get_lines(x)\n",
      "#    print lines\n",
      "    for line_id,l in enumerate(lines):\n",
      "        matches = []\n",
      "        for match in pattern.finditer(l):\n",
      "            matches.append(match.group(0))\n",
      "            w = match.group(1)\n",
      "            w = clean_word(w)\n",
      "            if w in words:\n",
      "                words[w].append((i,line_id))\n",
      "            else:\n",
      "                words[w] = [(i,l)]\n",
      "        assert l==''.join(matches)\n",
      "\n",
      "        \n",
      "\n",
      "# <codecell>\n",
      "\n",
      "re.match('\\([^(]','((')\n",
      "\n",
      "# <codecell>\n",
      "import csv\n",
      "def unicode_csv_reader(utf8_data, dialect=csv.excel, **kwargs):\n",
      "      csv_reader = csv.reader(utf8_data, dialect=dialect, **kwargs)\n",
      "      for row in csv_reader:\n",
      "          yield [unicode(cell, 'utf-8') for cell in row]\n",
      "old = unicode_csv_reader('rashid-dev.csv')\n",
      "\n",
      "def update_okays():\n",
      "    okay_dev={}\n",
      "    reader = unicode_csv_reader(open('okay-dev.csv'))\n",
      "    for transliteration,devanagari in reader:\n",
      "        okay_dev[transliteration]=devanagari\n",
      "\n",
      "    reader = unicode_csv_reader(open('rashid-dev.csv'))\n",
      "    for ok,devanagari,transliteration,count,meter,replacement in reader:\n",
      "        if ok=='x':\n",
      "            okay_dev[transliteration] = devanagari\n",
      "\n",
      "    with codecs.open('okay-dev.csv','w','utf8') as f:        \n",
      "        for k,v in okay_dev.iteritems():\n",
      "            f.write(k+u','+v+'\\n') #generate new csv\n",
      "#            print k,v\n",
      "    return okay_dev\n",
      "\n",
      "def regenerate():\n",
      "    \n",
      "    diacritics = myparser.Parser('diacritics.yaml')\n",
      "    devanagari = myparser.Parser('devanagari.yaml')\n",
      "    urdu = myparser.Parser('urdu.yaml')\n",
      "    um=myparser.Parser('urdu-meter.yaml')\n",
      "    okays = update_okays()\n",
      "    print 'okays is ',len(okays)\n",
      "\n",
      "    output=u\"ok,devanagari,transliteration,count,meter,replacement\\n\"\n",
      "#    for w in sorted(words, key=lambda k: len(words[k]), reverse=True):\n",
      "    for w in sorted(words, key=lambda k: len(words[k]), reverse=True):\n",
      "\n",
      "   #     print w\n",
      "        dev = devanagari.parse(w)\n",
      "        okay=''\n",
      "        if w in okays:\n",
      " #          print 'yes'\n",
      "            if okays[w] ==dev:\n",
      "                okay='x'\n",
      "            else:\n",
      "                print 'warning ',w,' is no longer', okays[w]\n",
      "                \n",
      "        output+=okay+','+dev+','+w+','+str(len(words[w]))+','+um.parse(w)+','+'\\n'\n",
      "\n",
      "        #print devanagari.parse(w),w,len(words[w])#print '\\n'.join(words.keys())\n",
      "    import codecs\n",
      "    with codecs.open('rashid-dev.csv','w','utf-8') as f:\n",
      "        f.write(output)\n",
      "regenerate()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<consonant> <long_vowel> <s> + <t> <long_vowel>\n",
        "<consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> <vowel> <vowel_nasal> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> <short_vowel> <h_char> + <consonant>\n",
        "<consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <vowel> <consonant> + <consonant> <vowel>\n",
        "<wb> <consonant> <short_vowel> <z> + <z> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<n> + <consonant>\n",
        "<wb> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n",
        "<k> + <k_group>\n",
        "<ch> + <ch_group>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <sibilant> + <consonant> <wb>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<vowel> <n> + <consonant>\n",
        "<consonant> + <n> <aa> <wb>\n",
        "<consonant> + <n> <e> <wb>\n",
        "<consonant> + <t> <aa> <wb>\n",
        "<consonant> + <t> <e> <wb>\n",
        "<consonant> + <t> <ii> <wb>\n",
        "<consonant> + <ain> <short_vowel> <wb>\n",
        "<short_vowel> <ain> + <consonant>\n",
        "<wb> <consonant> <short_vowel> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n",
        "okays is "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2326\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tamaashaa-gah-e laalah-zaar  is no longer \u0924\u092e\u093e\u0936\u093e\u0917\u0939\u2010\u090f\u2010\u0932\u093e\u0932\u093e\u091c\u093c\u093e\u0930\n",
        "warning  aarzuu  is no longer \u0906\u0930\u094d\u091c\u093c\u0942\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aasmaa;n  is no longer \u0906\u0938\u094d\u092e\u093e\u0901\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " daastaa;n  is no longer \u0926\u093e\u0938\u094d\u0924\u093e\u0901\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rassii  is no longer \u0930\u0938\u094d\u0938\u0940\n",
        "warning  u;t;thii  is no longer \u0909\u091f\u094d\u0920\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aarzuu))e;n  is no longer \u0906\u0930\u094d\u091c\u093c\u0941\u090f\u0901\n",
        "warning  aarzuu))o;n  is no longer \u0906\u0930\u094d\u091c\u093c\u0941\u0913\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tumhe;n  is no longer \u0924\u0941\u092e\u094d\u0939\u0947\u0902\n",
        "warning  patthar  is no longer \u092a\u0924\u094d\u0925\u0930\n",
        "warning  justajuu  is no longer \u091c\u0941\u0938\u094d\u0924\u091c\u0942\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mallaa;h  is no longer \u092e\u0932\u094d\u0932\u093e\u0939\n",
        "warning  takraar  is no longer \u0924\u0915\u094d\u0930\u093e\u0930\n",
        "warning  raste  is no longer \u0930\u0938\u094d\u0924\u0947\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dukkaan  is no longer \u0926\u0941\u0915\u094d\u0915\u093e\u0928\n",
        "warning  ishtiraakii  is no longer \u0907\u0936\u094d\u0924\u093f\u0930\u093e\u0915\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " afrang  is no longer \u0905\u092b\u093c\u094d\u0930\u0902\u0917\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " mastuur  is no longer \u092e\u0938\u094d\u0924\u0942\u0930\n",
        "warning  la;z;zaat  is no longer \u0932\u091c\u093c\u094d\u091c\u093c\u093e\u0924\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " i;xtiyaar  is no longer \u0907\u0916\u093c\u094d\u0924\u093f\u092f\u093e\u0930\n",
        "warning  vaa-raftah  is no longer \u0935\u093e\u0930\u092b\u093c\u094d\u0924\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tajallii  is no longer \u0924\u091c\u0932\u094d\u0932\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ;hurriyat  is no longer \u0939\u0941\u0930\u094d\u0930\u093f\u092f\u0924\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " vaa-bastah  is no longer \u0935\u093e\u092c\u0938\u094d\u0924\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ta.sviir  is no longer \u0924\u0938\u094d\u0935\u0940\u0930\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " rakkhaa  is no longer \u0930\u0915\u094d\u0916\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :tayyaarah  is no longer \u0924\u092f\u094d\u092f\u093e\u0930\u093e\n",
        "warning  tumhaare  is no longer \u0924\u0941\u092e\u094d\u0939\u093e\u0930\u0947\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ((ushshaaq  is no longer \u0909\u0936\u094d\u0936\u093e\u0915\u093c\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " parastaar  is no longer \u092a\u0930\u0938\u094d\u0924\u093e\u0930\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tumhaaraa  is no longer \u0924\u0941\u092e\u094d\u0939\u093e\u0930\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dostii  is no longer \u0926\u094b\u0938\u094d\u0924\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " avvalii;n  is no longer \u0905\u0935\u094d\u0935\u0932\u0940\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ((a:t:taar  is no longer \u0905\u0924\u094d\u0924\u093e\u0930\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ashko;n  is no longer \u0905\u0936\u094d\u0915\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dara;xto;n  is no longer \u0926\u0930\u0916\u093c\u094d\u0924\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " paristaar  is no longer \u092a\u0930\u093f\u0938\u094d\u0924\u093e\u0930\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " royaa-e aasmaanii  is no longer \u0930\u094b\u092f\u093e\u2010\u090f\u2010\u0906\u0938\u094d\u092e\u093e\u0928\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " shabistaano;n  is no longer \u0936\u092c\u093f\u0938\u094d\u0924\u093e\u0928\u094b\u0902\n",
        "warning  himmat-e naa-;xvub  is no longer \u0939\u093f\u092e\u094d\u092e\u0924\u2010\u090f\u2010\u0928\u093e\u0916\u093c\u0941\u092c\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tumhaarii  is no longer \u0924\u0941\u092e\u094d\u0939\u093e\u0930\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ittifaaqaat  is no longer \u0907\u0924\u094d\u0924\u093f\u092b\u093c\u093e\u0915\u093c\u093e\u0924\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gulistaa;n  is no longer \u0917\u0941\u0932\u093f\u0938\u094d\u0924\u093e\u0901\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " .sub;he;n  is no longer \u0938\u0941\u092c\u094d\u0939\u0947\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " roz-e avvalii;n  is no longer \u0930\u094b\u091c\u093c\u2010\u090f\u2010\u0905\u0935\u094d\u0935\u0932\u0940\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " joyandah-e tamkiin  is no longer \u091c\u094b\u092f\u0902\u0926\u0939\u2010\u090f\u2010\u0924\u092e\u0915\u0940\u0928\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " shab-e raftah  is no longer \u0936\u092c\u2010\u090f\u2010\u0930\u092b\u093c\u094d\u0924\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " u;t;the;n  is no longer \u0909\u091f\u094d\u0920\u0947\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aarzuu-e vi.saal-e ma((nii  is no longer \u0906\u0930\u094d\u091c\u093c\u0942\u2010\u090f\u2010\u0935\u093f\u0938\u093e\u0932\u2010\u090f\u2010\u092e\u093e\u0928\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sar-e bistar-e sanjaab  is no longer \u0938\u0930\u2010\u090f\u2010\u092c\u093f\u0938\u094d\u0924\u0930\u2010\u090f\u2010\u0938\u0902\u091c\u093e\u092c\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ummiid  is no longer \u0909\u092e\u094d\u092e\u0940\u0926\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ;xvaab-e la;z;zat-aagii;n  is no longer \u0916\u093c\u094d\u0935\u093e\u092c\u2010\u090f\u2010\u0932\u091c\u093c\u094d\u091c\u093c\u0924\u0906\u0917\u0940\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " afrangii  is no longer \u0905\u092b\u093c\u094d\u0930\u0902\u0917\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ishtiraak-e giraa;n-bahaa  is no longer \u0907\u0936\u094d\u0924\u093f\u0930\u093e\u0915\u2010\u090f\u2010\u0917\u093f\u0930\u093e\u0901\u092c\u0939\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " la;z;zat-e tasliim  is no longer \u0932\u091c\u093c\u094d\u091c\u093c\u0924\u2010\u090f\u2010\u0924\u0938\u094d\u0932\u0940\u092e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " sabzo;n  is no longer \u0938\u092c\u094d\u091c\u093c\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dosto;n  is no longer \u0926\u094b\u0938\u094d\u0924\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " lab-haa-e azal-tishnah  is no longer \u0932\u092c\u0939\u093e\u2010\u090f\u2010\u0905\u091c\u093c\u0932\u0924\u093f\u0936\u094d\u0928\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aarzuu-mandii  is no longer \u0906\u0930\u094d\u091c\u093c\u0942\u092e\u0902\u0926\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " farishto;n  is no longer \u092b\u093c\u0930\u093f\u0936\u094d\u0924\u094b\u0902\n",
        "warning  kanakhyo;n  is no longer \u0915\u0928\u0916\u094d\u092f\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ((aruus-e javaa;n-saal-e fardaa  is no longer \u0905\u0930\u0942\u0938\u2010\u090f\u2010\u091c\u0935\u093e\u0901\u0938\u093e\u0932\u2010\u090f\u2010\u092b\u093c\u0930\u094d\u0926\u093e\n",
        "warning  shaqiiq-o-nastaran  is no longer \u0936\u0915\u093c\u0940\u0915\u093c\u2010\u0913\u2010\u0928\u0938\u094d\u0924\u0930\u0928\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gumbado;n  is no longer \u0917\u0941\u092e\u094d\u092c\u0926\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aastaa;n  is no longer \u0906\u0938\u094d\u0924\u093e\u0901\n",
        "warning  ba;xshe;n  is no longer \u092c\u0916\u093c\u094d\u0936\u0947\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " himmat-e yazdaa;n  is no longer \u0939\u093f\u092e\u094d\u092e\u0924\u2010\u090f\u2010\u092f\u091c\u093c\u094d\u0926\u093e\u0901\n",
        "warning  raaste  is no longer \u0930\u093e\u0938\u094d\u0924\u0947\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dara;xshaa;n  is no longer \u0926\u0930\u0916\u093c\u094d\u0936\u093e\u0901\n",
        "warning  la;z;zato;n  is no longer \u0932\u091c\u093c\u094d\u091c\u093c\u0924\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ak;sar  is no longer \u0905\u0915\u094d\u0938\u0930\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " shab-haa-e zimistaa;n  is no longer \u0936\u092c\u0939\u093e\u2010\u090f\u2010\u091c\u093c\u093f\u092e\u093f\u0938\u094d\u0924\u093e\u0901\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " garmaa))e;nge  is no longer \u0917\u0930\u094d\u092e\u093e\u090f\u0902\u0917\u0947\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " patto;n  is no longer \u092a\u0924\u094d\u0924\u094b\u0902\n",
        "warning  shabistaa;n  is no longer \u0936\u092c\u093f\u0938\u094d\u0924\u093e\u0901\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " daste  is no longer \u0926\u0938\u094d\u0924\u0947\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ;xvurshiid  is no longer \u0916\u093c\u0941\u0930\u094d\u0936\u0940\u0926\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :tilismii  is no longer \u0924\u093f\u0932\u093f\u0938\u094d\u092e\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " parasto;n  is no longer \u092a\u0930\u0938\u094d\u0924\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " istibdaad  is no longer \u0907\u0938\u094d\u0924\u093f\u092c\u0926\u093e\u0926\n",
        "warning  alvand  is no longer \u0905\u0932\u094d\u0935\u0902\u0926\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " be-i;xtiyaarii  is no longer \u092c\u0947\u0907\u0916\u093c\u094d\u0924\u093f\u092f\u093e\u0930\u0940\n",
        "warning  aa;gosh-e aarzuu-mand  is no longer \u0906\u0917\u093c\u094b\u0936\u2010\u090f\u2010\u0906\u0930\u094d\u091c\u093c\u0942\u092e\u0902\u0926\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " uftaadah  is no longer \u0909\u092b\u093c\u094d\u0924\u093e\u0926\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dushmano;n  is no longer \u0926\u0941\u0936\u094d\u092e\u0928\u094b\u0902\n",
        "warning  rakkhii  is no longer \u0930\u0915\u094d\u0916\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " havas-parastii  is no longer \u0939\u0935\u0938\u092a\u0930\u0938\u094d\u0924\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ((ishqii  is no longer \u0907\u0936\u094d\u0915\u093c\u0940\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ummiid-e zifaaf  is no longer \u0909\u092e\u094d\u092e\u0940\u0926\u2010\u090f\u2010\u091c\u093c\u093f\u092b\u093c\u093e\u092b\u093c\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pastiyo;n  is no longer \u092a\u0938\u094d\u0924\u093f\u092f\u094b\u0902\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " gum-gashtah  is no longer \u0917\u0941\u092e\u0917\u0936\u094d\u0924\u093e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " aarzuu-e saliim  is no longer \u0906\u0930\u094d\u091c\u093c\u0942\u2010\u090f\u2010\u0938\u0932\u0940\u092e\n",
        "warning "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " jalvah-gah-e raaz  is no longer \u091c\u0932\u0935\u093e\u0917\u0939\u2010\u090f\u2010\u0930\u093e\u091c\u093c\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devanagari = myparser.Parser('devanagari.yaml')\n",
      "print devanagari.parse(' tah ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<consonant> <long_vowel> <s> + <t> <long_vowel>\n",
        "<consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> <vowel> <vowel_nasal> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> <short_vowel> <h_char> + <consonant>\n",
        "<consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <vowel> <consonant> + <consonant> <vowel>\n",
        "<wb> <consonant> <short_vowel> <z> + <z> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<n> + <consonant>\n",
        "<wb> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n",
        "<k> + <k_group>\n",
        "<ch> + <ch_group>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <sibilant> + <consonant> <wb>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<vowel> <n> + <consonant>\n",
        "<consonant> + <n> <aa> <wb>\n",
        "<consonant> + <n> <e> <wb>\n",
        "<consonant> + <t> <aa> <wb>\n",
        "<consonant> + <t> <e> <wb>\n",
        "<consonant> + <t> <ii> <wb>\n",
        "<consonant> + <ain> <short_vowel> <wb>\n",
        "<short_vowel> <ain> + <consonant>\n",
        "<wb> <consonant> <short_vowel> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n",
        " \u0924\u093e \n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devanagari=myparser.Parser('devanagari.yaml')\n",
      "print devanagari.parse(\"vaqt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<wb> <consonant> <short_vowel> <h_char> + <consonant> <wb>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <long_vowel> <wb>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant> <wb>\n",
        "<n> + <consonant>\n",
        "<consonant> + <consonant>\n",
        "<k> + <k_group>\n",
        "<ch> + <ch_group>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <sibilant> + <consonant> <wb>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<vowel> <n> + <consonant>\n",
        "<consonant> + <n> <aa> <wb>\n",
        "<consonant> + <n> <e> <wb>\n",
        "<consonant> + <t> <aa> <wb>\n",
        "<consonant> + <t> <e> <wb>\n",
        "<consonant> + <t> <ii> <wb>\n",
        "<consonant> + <ain> <short_vowel> <wb>\n",
        "<short_vowel> <ain> + <consonant>\n",
        "<wb> <consonant> <short_vowel> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n",
        "\u0935\u0915\u093c\u094d\u0924\n"
       ]
      }
     ],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}